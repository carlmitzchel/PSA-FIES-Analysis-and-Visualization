{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "<a href=\"https://archive.ics.uci.edu/ml/datasets/online+retail\">Online retail</a> is a transnational dataset which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n",
    "\n",
    "## Source\n",
    "UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/online+retail\n",
    "\n",
    "## Business Goal\n",
    "To segment the Customers based on RFM so that the company can target its customers efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T10:16:54.581653Z",
     "start_time": "2020-11-01T10:16:54.570637Z"
    }
   },
   "source": [
    "## Methodology\n",
    "\n",
    "1. [Reading and Understanding the Data](#1) <br>\n",
    "    a. Creating a Data Dictionary\n",
    "2. [Data Cleaning](#2)\n",
    "3. [Data Preparation](#3) <br>\n",
    "    a. Scaling Variables\n",
    "4. [Model Building](#4) <br>\n",
    "    a. K-means Clustering <br>\n",
    "    b. Finding the Optimal K\n",
    "5. [Final Analysis](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "### 1 : Reading and Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:00.815005Z",
     "start_time": "2020-11-01T13:13:56.682079Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required libraries for dataframe and visualization\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import plotly as py \n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# import required libraries for clustering\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import cut_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:02.085599Z",
     "start_time": "2020-11-01T13:14:00.818009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the data on which analysis needs to be done\n",
    "retail = pd.read_csv('OnlineRetail.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Dictionary \n",
    "\n",
    "First Header  | Definition    |  Description  | Data Type\n",
    "------------- | ------------- | ------------- | -------------\n",
    "InvoiceNo  | Invoice number | A 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation. | Nominal\n",
    "StockCode | Product (item) code | A 5-digit integral number uniquely assigned to each distinct product. | Nominal\n",
    "Description | Product (item) name | Name of Product | Nominal\n",
    "Quantity | Quantity | The quantities of each product (item) per transaction | Numeric\n",
    "InvoiceDate | Invoice Date and time | The day and time when each transaction was generated. | Numeric\n",
    "UnitPrice | Unit price | Product price per unit in sterling. | Numeric\n",
    "CustomerID | Customer number | A 5-digit integral number uniquely assigned to each customer. | Nominal\n",
    "Country | Country name | The name of the country where each customer resides. | Nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show all columns on output\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explanation:` First, the dataset is loaded into Jupyter notebook, and the initial step was to show the first ten rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:02.105605Z",
     "start_time": "2020-11-01T13:14:02.093577Z"
    }
   },
   "outputs": [],
   "source": [
    "# shape of df\n",
    "retail.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:02.490124Z",
     "start_time": "2020-11-01T13:14:02.373115Z"
    }
   },
   "outputs": [],
   "source": [
    "# df description\n",
    "retail.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "### 2 : Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting InvoiceDate\n",
    "\n",
    "retail['InvoiceDate'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting InvoiceDate to datetime\n",
    "\n",
    "retail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting InvoiceDate\n",
    "\n",
    "retail['InvoiceDate'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:02.686138Z",
     "start_time": "2020-11-01T13:14:02.492125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculating the Missing Values % contribution in DF\n",
    "df_null = round(100*(retail.isnull().sum())/len(retail), 2)\n",
    "df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the df_null\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.barplot(x=df_null.index, y=df_null.values, alpha=0.8)\n",
    "plt.title('Missing Values (Pre Cleaning)')\n",
    "plt.ylabel('Missing Values %')\n",
    "plt.xlabel('Columns')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:02.884178Z",
     "start_time": "2020-11-01T13:14:02.691137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Droping rows having missing values\n",
    "retail = retail.dropna()\n",
    "retail.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explanation:` The missing values were scanned then it was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Missing Values % contribution in DF\n",
    "retail.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a barplot for the retail to check if null values still exist\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.barplot(x=retail.columns, y=retail.isna().sum().values, alpha=0.8)\n",
    "plt.title('Missing Values (Post Cleaning)')\n",
    "plt.ylabel('Missing Values')\n",
    "plt.xlabel('Columns')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explanation:` The bar chart was represented by computing the percentage of missing values by column before and after preprocessing\n",
    "\n",
    "Most of the missing values are in the ‘CustomerID’ column, and few are in the ‘Description’ column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:03.209183Z",
     "start_time": "2020-11-01T13:14:02.890175Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changing the datatype of Customer Id as per Business understanding\n",
    "retail['CustomerID'] = retail['CustomerID'].astype(str)\n",
    "retail.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "### 3 : Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customers will be analyzed based on 3 factors:\n",
    "- R (Recency): Number of days since last purchase\n",
    "- F (Frequency): Number of tracsactions\n",
    "- M (Monetary): Total amount of transactions (revenue contributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:03.401194Z",
     "start_time": "2020-11-01T13:14:03.215186Z"
    }
   },
   "outputs": [],
   "source": [
    "# New Attribute : Monetary\n",
    "retail['Amount'] = retail['Quantity'] * retail['UnitPrice']\n",
    "rfm_m = retail.groupby('CustomerID')['Amount'].sum()\n",
    "rfm_m = rfm_m.reset_index()\n",
    "rfm_m.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:03.494236Z",
     "start_time": "2020-11-01T13:14:03.404192Z"
    }
   },
   "outputs": [],
   "source": [
    "# New Attribute : Frequency\n",
    "rfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\n",
    "rfm_f = rfm_f.reset_index()\n",
    "rfm_f.columns = ['CustomerID', 'Frequency']\n",
    "rfm_f.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:03.522238Z",
     "start_time": "2020-11-01T13:14:03.496236Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merging the two dfs\n",
    "rfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n",
    "print(rfm.shape)\n",
    "rfm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:03.759256Z",
     "start_time": "2020-11-01T13:14:03.525239Z"
    }
   },
   "outputs": [],
   "source": [
    "# New Attribute : Recency\n",
    "# Convert to datetime to proper datatype\n",
    "retail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.278371Z",
     "start_time": "2020-11-01T13:14:03.763256Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the maximum date to know the last transaction date\n",
    "max_date = max(retail['InvoiceDate'])\n",
    "max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.318375Z",
     "start_time": "2020-11-01T13:14:05.281374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the difference between max date and transaction date\n",
    "retail['Diff'] = max_date - retail['InvoiceDate']\n",
    "retail.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.386380Z",
     "start_time": "2020-11-01T13:14:05.322375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute last transaction date to get the recency of customers\n",
    "rfm_p = retail.groupby('CustomerID')['Diff'].min()\n",
    "rfm_p = rfm_p.reset_index()\n",
    "rfm_p.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.406382Z",
     "start_time": "2020-11-01T13:14:05.389387Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract number of days only\n",
    "rfm_p['Diff'] = rfm_p['Diff'].dt.days\n",
    "rfm_p.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.457385Z",
     "start_time": "2020-11-01T13:14:05.411382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge tha dataframes to get the final RFM dataframe\n",
    "rfm = pd.merge(rfm, rfm_p , on='CustomerID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n",
    "rfm.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot to identify outliers in the dataset\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=rfm['Amount'], color='skyblue')\n",
    "plt.title('Amount Boxplot')\n",
    "plt.xlabel('Amount')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=rfm['Frequency'], color='lightgreen')\n",
    "plt.title('Frequency Boxplot')\n",
    "plt.xlabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=rfm['Recency'], color='salmon')\n",
    "plt.title('Recency Boxplot')\n",
    "plt.xlabel('Recency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explanation:` \n",
    "\n",
    "Boxplot on the other hand, helped us with summary statistics like easily identifying the median, quartile, and most especially, it is great for spotting outliers and understanding the data spread.\n",
    "\n",
    "Similarly, like the histogram, it showed potential outliers distributed by identifying points that are isolated and far from the point clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for the distribution of at least two key numerical features\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(rfm['Amount'], color='skyblue', kde=True)\n",
    "plt.title('Amount Distribution')\n",
    "plt.xlabel('Amount')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(rfm['Frequency'], color='lightgreen', kde=True)\n",
    "plt.title('Frequency Distribution')\n",
    "plt.xlabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(rfm['Recency'], color='salmon', kde=True)\n",
    "plt.title('Recency Distribution')\n",
    "plt.xlabel('Recency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explanation:`\n",
    "\n",
    "Amount and Frequency both show a highly skewed distribution with numerous outliers, suggesting that a few customers make very large transactions or purchase very frequently, in contrast to the majority.\n",
    "\n",
    "Recency is less skewed but still shows variability, with most customers being more recent in their activity, but some haven’t made purchases for a long time.\n",
    "\n",
    "The histogram focuses on the distribution of a single variable, and we could understand the data through the skewness, normality, or multimodality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap to show relationships between numerical variables\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(rfm.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explanation:`\n",
    "\n",
    "The correlation heatmap helped us in which features or variables have a strong relationship or correlation with each other. When reviewing the correlation heatmap it gives\n",
    "\n",
    "We found a positive correlation with the Amount and Frequency that we interpret as those customers who purchase more, spends more money.\n",
    "\n",
    "Low correlation of CustomerID shows that it is trivial or it doesn’t correlate closely with features such as Amount, Frequency, and Recency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rescaling the Attributes\n",
    "\n",
    "It is extremely important to rescale the variables so that they have a comparable scale.<br>\n",
    "There are two common ways of rescaling:\n",
    "\n",
    "1. Min-Max scaling \n",
    "2. Standardization (mean-0, sigma-1) \n",
    "\n",
    "Here we execute Standard Scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density Plot Before Scaling\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.kdeplot(rfm['Amount'], color='skyblue', fill=True)\n",
    "plt.title('Amount Distribution')\n",
    "plt.xlabel('Amount')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.kdeplot(rfm['Frequency'], color='lightgreen', fill=True)\n",
    "plt.title('Frequency Distribution')\n",
    "plt.xlabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.kdeplot(rfm['Recency'], color='salmon', fill=True)\n",
    "plt.title('Recency Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explanation:`\n",
    "\n",
    "Before Scaling: The data for Amount, Frequency, and Recency are on vastly different scales.\n",
    "\n",
    " For example, Amount is spread across thousands, while Recency could span hundreds of days, and Frequency ranges from single digits to a few hundred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.483386Z",
     "start_time": "2020-11-01T13:14:05.460385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rescaling the Attributes\n",
    "rfm_df = rfm[['Amount', 'Frequency', 'Recency']]\n",
    "\n",
    "# Instantiate\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit_transform\n",
    "rfm_df_scaled = scaler.fit_transform(rfm_df)\n",
    "rfm_df_scaled = pd.DataFrame(rfm_df_scaled)\n",
    "rfm_df_scaled.shape\n",
    "\n",
    "rfm_df_scaled.columns = ['Amount', 'Frequency', 'Recency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density Plot After Scaling\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.kdeplot(rfm_df_scaled['Amount'], color='skyblue', fill=True)\n",
    "plt.title('Amount Distribution')\n",
    "plt.xlabel('Amount')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.kdeplot(rfm_df_scaled['Frequency'], color='lightgreen', fill=True)\n",
    "plt.title('Frequency Distribution')\n",
    "plt.xlabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.kdeplot(rfm_df_scaled['Recency'], color='salmon', fill=True)\n",
    "plt.title('Recency Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explanation:`\n",
    "\n",
    "After Standard Scaler: After applying the Standard Scaler (mean of 0, standard deviation of 1), all variables are transformed to a standard distribution. \n",
    "\n",
    "This ensures that they have comparable scales while maintaining the differences between high and low values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">Execute MinMax Scaling in the next box</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Rescaling the Attributes\n",
    "rfm_df = rfm[['Amount', 'Frequency', 'Recency']]\n",
    "\n",
    "# Instantiate \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit_transform\n",
    "rfm_df_scaled = scaler.fit_transform(rfm_df)\n",
    "rfm_df_scaled = pd.DataFrame(rfm_df_scaled)\n",
    "rfm_df_scaled.shape\n",
    "\n",
    "rfm_df_scaled.columns = ['Amount', 'Frequency', 'Recency']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density Plot After Scaling\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.kdeplot(rfm_df_scaled['Amount'], color='skyblue', fill=True)\n",
    "plt.title('Amount Distribution')\n",
    "plt.xlabel('Amount')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.kdeplot(rfm_df_scaled['Frequency'], color='lightgreen', fill=True)\n",
    "plt.title('Frequency Distribution')\n",
    "plt.xlabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.kdeplot(rfm_df_scaled['Recency'], color='salmon', fill=True)\n",
    "plt.title('Recency Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`After MinMax Scaling`: MinMax scaling brings all the values into the range [0, 1], which is helpful for models sensitive to the magnitude of input values, especially clustering algorithms like K-means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df_scaled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explain why this transformation is necessary for the next steps of the analysis: \n",
    "`\n",
    "\n",
    "Clustering Algorithms (like K-means) are highly sensitive to the scale of the data. Variables on different scales can dominate the distance calculations, leading to biased clusters.\n",
    "\n",
    "Standard Scaling helps preserve the original distribution but makes variables comparable, which is ideal for distance-based algorithms.\n",
    "\n",
    "MinMax Scaling is crucial when the range of variables is important for algorithm stability, ensuring no variable dominates due to large ranges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "### 4 : Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.<br>\n",
    "\n",
    "The algorithm works as follows:\n",
    "\n",
    "- First we initialize k points, called means, randomly.\n",
    "- We categorize each item to its closest mean and we update the mean’s coordinates, which are the averages of the items categorized in that mean so far.\n",
    "- We repeat the process for a given number of iterations and at the end, we have our clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.629395Z",
     "start_time": "2020-11-01T13:14:05.508388Z"
    }
   },
   "outputs": [],
   "source": [
    "# k-means with some arbitrary k\n",
    "Kmeans = KMeans(n_clusters=4, max_iter=50)\n",
    "Kmeans.fit(rfm_df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:14:05.651399Z",
     "start_time": "2020-11-01T13:14:05.644399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a K-means function here\n",
    "def K_Means(X, n):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    model = KMeans(n)\n",
    "    model.fit(X)\n",
    "    cluster_labels = model.predict(X)\n",
    "    cent = model.cluster_centers_\n",
    "    return cluster_labels, cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_labels, cent = K_Means(rfm_df, 3)\n",
    "kmeans = pd.DataFrame(clust_labels)\n",
    "rfm_df.insert((rfm_df.shape[1]), 'kmeans', kmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T13:53:55.898917Z",
     "start_time": "2020-11-01T13:53:55.746885Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot your clusters\n",
    "def Plot3dClustering(n, X, type_c):\n",
    "    data = []\n",
    "    clusters = []\n",
    "    colors = ['rgb(228,26,28)', 'rgb(55,126,184)', 'rgb(77,175,74)']\n",
    "    \n",
    "    for i in range(n):\n",
    "        name = i\n",
    "        color = colors[i]\n",
    "        x = X[X[type_c] == i]['Amount']\n",
    "        y = X[X[type_c] == i]['Frequency']\n",
    "        z = X[X[type_c] == i]['Recency']\n",
    "        \n",
    "        trace = dict(\n",
    "            name = name,\n",
    "            x = x, y = y, z = z,\n",
    "            type = 'scatter3d',\n",
    "            mode = 'markers',\n",
    "            marker = dict(size = 3, color = color, line = dict(width = 0)))\n",
    "        data.append(trace)\n",
    "        \n",
    "        cluster = dict(\n",
    "            color = color,\n",
    "            opacity = 0.1,\n",
    "            type = 'mesh3d',\n",
    "            alphahull = 7,\n",
    "            name = \"y\",\n",
    "            x = x, y = y, z = z)\n",
    "        data.append(cluster)\n",
    "        \n",
    "    layout = dict(\n",
    "        width = 800,\n",
    "        height = 550,\n",
    "        autosize = False,\n",
    "        title = '3D Clustering Plot',\n",
    "        scene = dict(\n",
    "            xaxis = dict(\n",
    "                gridcolor = 'rgb(255, 255, 255)',\n",
    "                zerolinecolor = 'rgb(255, 255, 255)',\n",
    "                showbackground = True,\n",
    "                title='Amount',\n",
    "                backgroundcolor = 'rgb(230, 230, 230)',\n",
    "                ),\n",
    "            yaxis = dict(\n",
    "                gridcolor = 'rgb(255, 255, 255)',\n",
    "                zerolinecolor = 'rgb(255, 255, 255)',\n",
    "                showbackground = True,\n",
    "                title='Frequency',\n",
    "                backgroundcolor = 'rgb(230, 230, 230)',\n",
    "                ),\n",
    "            zaxis = dict(\n",
    "                gridcolor = 'rgb(255, 255, 255)',\n",
    "                zerolinecolor = 'rgb(255, 255, 255)',\n",
    "                showbackground = True,\n",
    "                title='Recency',\n",
    "                backgroundcolor = 'rgb(230, 230, 230)',\n",
    "                ),\n",
    "            aspectratio = dict(x=1, y=1, z=0.7),\n",
    "            aspectmode = 'manual'\n",
    "        ),\n",
    "    )\n",
    "        \n",
    "    fig = dict(data = data, layout = layout)\n",
    "    iplot(fig, filename='3d-scatter-colorscale', validate=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot3dClustering(n=3, X=rfm_df, type_c='kmeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Describe the characteristics of the 3D Scatter Plot\n",
    "`\n",
    "\n",
    "The data points are mainly differentiated by Recency, with clear divisions between recent, moderately recent, and older transactions.\n",
    "\n",
    "Amount and Frequency also contribute to cluster differentiation, especially for older, high-amount transactions (green) versus more recent, low-amount transactions (blue and red).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Describe the characteristics of each cluster and the clustering results based on the visualization.\n",
    "`\n",
    "\n",
    "Red Cluster (central, vertical stretch): Represents transactions or events with varying Recency but generally low Frequency. The Amount stays moderate, ranging from 0 to 100k. These could be regular but infrequent transactions happening over a wide range of time periods.\n",
    "\n",
    "Green Cluster (spread at the base): Represents older transactions (low Recency), with a broad range in Frequency and Amount. Some transactions in this group have high amounts (up to 250k), suggesting less frequent but larger, older transactions.\n",
    "\n",
    "Blue Cluster (top, stacked): Represents recent transactions with low Frequency and smaller Amount values (up to 50k). These are more recent events but occur less frequently and involve smaller monetary amounts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Centroid Plot\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Centroid Plot')\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.scatter(rfm_df['Amount'], rfm_df['Frequency'], c=rfm_df['kmeans'], cmap='rainbow')\n",
    "plt.scatter(cent[:,0], cent[:,1], c='black', s=300, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">Finding the Optimal Number of Clusters</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elbow Curve to get the right number of Clusters\n",
    "A fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. The Elbow Method is one of the most popular methods to determine this optimal value of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-01T11:11:02.144287Z",
     "start_time": "2020-11-01T11:11:01.193847Z"
    }
   },
   "outputs": [],
   "source": [
    "X = rfm_df\n",
    "wcss = []\n",
    "for i in range(1,8):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=7, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1,8), wcss)\n",
    "plt.title('Elbow Method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Visualize silhouette score for each cluster using a Silhouette plot\n",
    "silhouette_avg = silhouette_score(rfm_df_scaled, rfm_df['kmeans'])\n",
    "print(f'Silhouette Score for 3 clusters: {silhouette_avg}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "# Calculate silhouette values\n",
    "sample_silhouette_values = silhouette_samples(rfm_df_scaled, rfm_df['kmeans'])\n",
    "\n",
    "# Create a silhouette plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "y_lower = 10\n",
    "for i in range(3):  # Change to 3 for 3 clusters\n",
    "    # Aggregate the silhouette scores for samples belonging to the current cluster\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values[rfm_df['kmeans'] == i]\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "    \n",
    "    # Get the size of the cluster\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    \n",
    "    # Compute the y position for the current cluster\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "    \n",
    "    # Fill the silhouette plot for the current cluster\n",
    "    plt.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values)\n",
    "    \n",
    "    # Label the silhouette plots\n",
    "    plt.text(-0.05, y_lower + 0.5 * size_cluster_i, f'Cluster {i + 1}')\n",
    "    \n",
    "    # Update the next y_lower position\n",
    "    y_lower = y_upper + 10  # 10 for the 10px separation between clusters\n",
    "\n",
    "plt.title('Silhouette Plot for the 3 Clusters')\n",
    "plt.xlabel('Silhouette Coefficient Values')\n",
    "plt.ylabel('Cluster Label')\n",
    "plt.axvline(x=silhouette_avg, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explanation:`The silhouette plot helps determine whether clusters are well-defined and can reveal points that may be misclassified or potential outliers. By examining the silhouette coefficient values, we can assess how well each point fits into its assigned cluster. Points with high values (close to 1) are well-clustered, while negative or near-zero values suggest poor clustering, misclassification, or the presence of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot revealed that:\n",
    "\n",
    "Overall, the silhouette score across all clusters is relatively high, signifying that the clustering is good overall and points are well-placed.\n",
    "\n",
    "However, a few points show low or negative silhouette values, particularly in Cluster 1, which may indicate potential outliers or points that are not well separated from other clusters. These points might benefit from further investigation or reassignment to other clusters, as they do not fit as neatly into the current grouping.\n",
    "\n",
    "In summary, the clustering is robust, but there are some instances of borderline points or possible outliers that may require attention to refine the model further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">Box Plots of Clusters created</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the plot\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Create a subplot for each feature\n",
    "for i, feature in enumerate(['Amount', 'Frequency', 'Recency'], 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    sns.boxplot(x='kmeans', y=feature, data=rfm_df)\n",
    "    plt.title(f'Boxplot of {feature} by Cluster')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Analysis:`\n",
    "\n",
    "- The box plot reveals a significant disparity in the spending behavior across the clusters.\n",
    "\n",
    "- Overall, the box plots highlight the distinct characteristics of each cluster in terms of spending habits, purchase frequency, and recency of transactions. Cluster 0 represents low spenders who shop infrequently but recently, while Cluster 1 consists of moderate spenders with a balanced shopping frequency. Cluster 2, on the other hand, captures high spenders who shop frequently but may have become less recent, indicating an opportunity for targeted marketing strategies to rekindle their engagement. This differentiation in customer behavior is essential for tailoring marketing efforts and improving customer relationship management strategies. ​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "## Step 5 : Final Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: red;\">Findings</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the distribution of data points across the clusters using pie chart\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "rfm_df['kmeans'].value_counts().plot.pie(autopct='%1.1f%%')\n",
    "plt.title('Cluster Distribution')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Explanation:`\n",
    "\n",
    "The pie chart shows the distribution of three customer clusters, with Cluster 0 accounting for 74.5%, Cluster 1 for 25.2%, and Cluster 2 for only 0.3%. These clusters are visually represented in the scatter plot, where Cluster 0 (blue) consists of customers who make frequent and recent purchases with high spending, dominating the plot. Cluster 1 (orange/red) includes occasional buyers with moderate frequency and recency, while Cluster 2 (green) represents a small group of inactive customers with low engagement, corresponding to its minimal share in the pie chart. The scatter plot thus reinforces the cluster sizes shown in the pie chart by depicting their purchasing behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name: 4CSC\n",
    "- Benjamin Francis Abadila\n",
    "- Angelo Dela Paz\n",
    "- Carl Mitzchel Padua\n",
    "- Edjin Jerney Payumo\n",
    "- Levin Jacob Sta. Cruz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
